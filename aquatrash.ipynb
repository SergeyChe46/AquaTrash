{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sergeyche/aquatrash?scriptVersionId=110191406\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nfrom tensorflow.keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.utils import class_weight","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:45.94223Z","iopub.execute_input":"2022-11-06T10:53:45.94274Z","iopub.status.idle":"2022-11-06T10:53:52.809415Z","shell.execute_reply.started":"2022-11-06T10:53:45.94266Z","shell.execute_reply":"2022-11-06T10:53:52.80843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/aquatrash/annotations.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.811275Z","iopub.execute_input":"2022-11-06T10:53:52.812029Z","iopub.status.idle":"2022-11-06T10:53:52.838245Z","shell.execute_reply.started":"2022-11-06T10:53:52.81199Z","shell.execute_reply":"2022-11-06T10:53:52.837356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.839651Z","iopub.execute_input":"2022-11-06T10:53:52.840019Z","iopub.status.idle":"2022-11-06T10:53:52.861436Z","shell.execute_reply.started":"2022-11-06T10:53:52.839983Z","shell.execute_reply":"2022-11-06T10:53:52.86062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '../input/aquatrash/Images'\nCLASSES = np.unique(df['class_name'])","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.864537Z","iopub.execute_input":"2022-11-06T10:53:52.864911Z","iopub.status.idle":"2022-11-06T10:53:52.872171Z","shell.execute_reply.started":"2022-11-06T10:53:52.864876Z","shell.execute_reply":"2022-11-06T10:53:52.871239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check class balance","metadata":{}},{"cell_type":"code","source":"df['class_name'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.873505Z","iopub.execute_input":"2022-11-06T10:53:52.874074Z","iopub.status.idle":"2022-11-06T10:53:52.886887Z","shell.execute_reply.started":"2022-11-06T10:53:52.874037Z","shell.execute_reply":"2022-11-06T10:53:52.885919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoder for categorical data","metadata":{}},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nlabel_binarizer.fit(df['class_name'])","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.888488Z","iopub.execute_input":"2022-11-06T10:53:52.88885Z","iopub.status.idle":"2022-11-06T10:53:52.899684Z","shell.execute_reply.started":"2022-11-06T10:53:52.888805Z","shell.execute_reply":"2022-11-06T10:53:52.89862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute class_weights for pay more attention to ","metadata":{}},{"cell_type":"code","source":"class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(df['class_name']), y=df['class_name'])\nclss_weights = dict(enumerate(class_weights))\nclss_weights","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.901327Z","iopub.execute_input":"2022-11-06T10:53:52.901681Z","iopub.status.idle":"2022-11-06T10:53:52.911215Z","shell.execute_reply.started":"2022-11-06T10:53:52.901647Z","shell.execute_reply":"2022-11-06T10:53:52.910364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I split data immediatelly","metadata":{}},{"cell_type":"code","source":"train_data, test_data = train_test_split(df, test_size=0.2, shuffle=True)\ntrain_data, valid_data = train_test_split(train_data, test_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.913938Z","iopub.execute_input":"2022-11-06T10:53:52.914334Z","iopub.status.idle":"2022-11-06T10:53:52.920978Z","shell.execute_reply.started":"2022-11-06T10:53:52.914301Z","shell.execute_reply":"2022-11-06T10:53:52.920063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This function will load each image, get absolute coords of bounding box and return them with binarizer label i.e. to_categorical.","metadata":{}},{"cell_type":"code","source":"def prepare_data(data):\n    images = []\n    coords = []\n    labels = []\n    for row in data.iloc:\n        # extract each row from .csv\n        image_name, start_x, start_y, end_x, end_y, label = row\n        # load an image for save it size and append to list store\n        image = tf.keras.utils.load_img(f'{BASE_PATH}/{image_name}')\n        image = tf.keras.utils.img_to_array(image)\n        height, width = image.shape[:2]\n        image = tf.image.resize(image, (224, 224))\n        # set coords of bounding box to absolute\n        abs_start_x = float(start_x) / width\n        abs_start_y = float(start_y) / height\n        abs_end_x = float(end_x) / width\n        abs_end_y = float(end_y) / height\n        images.append(image)\n        coords.append((abs_start_x, abs_start_y, abs_end_x, abs_end_y))\n        labels.append(label)\n    images = np.array(images, dtype='float32') / 255\n    coords = np.array(coords, dtype='float32')\n    labels = label_binarizer.transform(labels)\n    \n    return images, coords, labels","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.922295Z","iopub.execute_input":"2022-11-06T10:53:52.924144Z","iopub.status.idle":"2022-11-06T10:53:52.933505Z","shell.execute_reply.started":"2022-11-06T10:53:52.92411Z","shell.execute_reply":"2022-11-06T10:53:52.932611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train model. For model I take VGG19 and add to FC outputs.","metadata":{}},{"cell_type":"code","source":"vgg = tf.keras.applications.vgg19.VGG19(\n    include_top=False,\n    input_shape=(224, 224, 3)\n)\n\nvgg.trainable = False\nflatten = Flatten()(vgg.output)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:52.939289Z","iopub.execute_input":"2022-11-06T10:53:52.939935Z","iopub.status.idle":"2022-11-06T10:53:56.598753Z","shell.execute_reply.started":"2022-11-06T10:53:52.939905Z","shell.execute_reply":"2022-11-06T10:53:56.597713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First output for bbox coords","metadata":{}},{"cell_type":"code","source":"bbox = Dropout(0.5)(flatten)\nbbox = Dense(512, activation='relu')(bbox)\nbbox = Dense(128, activation='relu')(bbox)\nbbox = Dropout(0.5)(bbox)\nbbox_result = Dense(4, activation='sigmoid', name='bbox_result')(bbox)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:53:56.599968Z","iopub.execute_input":"2022-11-06T10:53:56.600319Z","iopub.status.idle":"2022-11-06T10:53:56.632445Z","shell.execute_reply.started":"2022-11-06T10:53:56.600285Z","shell.execute_reply":"2022-11-06T10:53:56.631614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second output for labels","metadata":{}},{"cell_type":"code","source":"label = Dropout(0.5)(flatten)\nlabel = Dense(512, activation='relu')(label)\nlabel = Dense(256, activation='relu')(label)\nlabel = Dropout(0.5)(label)\nlabel_result = Dense(len(label_binarizer.classes_), activation='softmax', name='label_result')(label)\n\nmodel = Model(vgg.input, [bbox_result, label_result])","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:58:06.624637Z","iopub.execute_input":"2022-11-06T10:58:06.625002Z","iopub.status.idle":"2022-11-06T10:58:06.662934Z","shell.execute_reply.started":"2022-11-06T10:58:06.624973Z","shell.execute_reply":"2022-11-06T10:58:06.662026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = {\n    \"label_result\": \"categorical_crossentropy\",\n    \"bbox_result\": \"mean_squared_error\",\n}\n\nloss_weights = {\n    \"label_result\": 1.0,\n    \"bbox_result\": 1.0\n}\n\nmodel.compile(loss=losses, optimizer=Adam(0.00007), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:58:06.665092Z","iopub.execute_input":"2022-11-06T10:58:06.665464Z","iopub.status.idle":"2022-11-06T10:58:06.676761Z","shell.execute_reply.started":"2022-11-06T10:58:06.665429Z","shell.execute_reply":"2022-11-06T10:58:06.67583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_coords, train_labels = prepare_data(train_data)\ntest_images, test_coords, test_labels = prepare_data(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:58:06.678207Z","iopub.execute_input":"2022-11-06T10:58:06.678612Z","iopub.status.idle":"2022-11-06T10:58:48.585535Z","shell.execute_reply.started":"2022-11-06T10:58:06.678562Z","shell.execute_reply":"2022-11-06T10:58:48.584544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Each output will have self target","metadata":{}},{"cell_type":"code","source":"train_targets = {\n    \"label_result\": train_labels,\n    \"bbox_result\": train_coords,\n}\n\ntest_targets = {\n    \"label_result\": test_labels,\n    \"bbox_result\": test_coords,\n}","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:58:48.588155Z","iopub.execute_input":"2022-11-06T10:58:48.588528Z","iopub.status.idle":"2022-11-06T10:58:48.593478Z","shell.execute_reply.started":"2022-11-06T10:58:48.588491Z","shell.execute_reply":"2022-11-06T10:58:48.592479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_images, train_targets,\n    validation_data=(test_images, test_targets),\n    epochs=100,\n    batch_size=16\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T10:58:48.594928Z","iopub.execute_input":"2022-11-06T10:58:48.595551Z","iopub.status.idle":"2022-11-06T11:00:41.598233Z","shell.execute_reply.started":"2022-11-06T10:58:48.595512Z","shell.execute_reply":"2022-11-06T11:00:41.597331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting accuracy and loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\nplt.plot(history.history['bbox_result_loss'], label='bbox_loss')\nplt.plot(history.history['label_result_loss'], label='label_loss')\n\nplt.plot(history.history['val_bbox_result_loss'], label='bbox_loss_val')\nplt.plot(history.history['val_label_result_loss'], label='label_loss_val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:00:41.600067Z","iopub.execute_input":"2022-11-06T11:00:41.600419Z","iopub.status.idle":"2022-11-06T11:00:41.845872Z","shell.execute_reply.started":"2022-11-06T11:00:41.600373Z","shell.execute_reply":"2022-11-06T11:00:41.844698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Time for predict","metadata":{}},{"cell_type":"code","source":" valid_images, valid_coords, valid_labels = prepare_data(valid_data)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:00:41.847296Z","iopub.execute_input":"2022-11-06T11:00:41.847649Z","iopub.status.idle":"2022-11-06T11:00:48.331227Z","shell.execute_reply.started":"2022-11-06T11:00:41.847613Z","shell.execute_reply":"2022-11-06T11:00:48.3301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(box_pred, label_pred) = model.predict(valid_images)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:00:48.332483Z","iopub.execute_input":"2022-11-06T11:00:48.332876Z","iopub.status.idle":"2022-11-06T11:00:48.728104Z","shell.execute_reply.started":"2022-11-06T11:00:48.332834Z","shell.execute_reply":"2022-11-06T11:00:48.727093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40, 20))\nfor i in range(1, 9):\n    plt.subplot(2, 4, i)\n    rand_idx = random.randint(0, len(valid_images)-1)\n    image = cv2.imread(BASE_PATH+'/'+valid_data['image_name'].iloc[rand_idx])\n    (start_x, start_y, end_x, end_y) = box_pred[rand_idx]\n    start_x = int(start_x*image.shape[1])\n    start_y = int(start_y*image.shape[0])\n    end_x = int(end_x*image.shape[1])\n    end_y = int(end_y*image.shape[0])\n    pred_label = CLASSES[np.argmax(label_pred[rand_idx])]\n    true_label = CLASSES[np.argmax(valid_labels[rand_idx])]\n    color = (0, 255, 0) if true_label==pred_label else (255, 0, 0)\n    cv2.putText(image, pred_label, (start_x, start_y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.5, (0, 255, 0), 2)\n    cv2.rectangle(image, (start_x, start_y), (end_x, end_y), color, 2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:37:11.776583Z","iopub.execute_input":"2022-11-06T11:37:11.777256Z","iopub.status.idle":"2022-11-06T11:37:17.459458Z","shell.execute_reply.started":"2022-11-06T11:37:11.77722Z","shell.execute_reply":"2022-11-06T11:37:17.458362Z"},"trusted":true},"execution_count":null,"outputs":[]}]}